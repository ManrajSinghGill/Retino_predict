{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:28.005438Z","iopub.execute_input":"2024-12-29T05:50:28.005769Z","iopub.status.idle":"2024-12-29T05:50:28.321039Z","shell.execute_reply.started":"2024-12-29T05:50:28.005737Z","shell.execute_reply":"2024-12-29T05:50:28.320173Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Importing Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\nfrom torchvision import models\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:28.322757Z","iopub.execute_input":"2024-12-29T05:50:28.323252Z","iopub.status.idle":"2024-12-29T05:50:31.512067Z","shell.execute_reply.started":"2024-12-29T05:50:28.323212Z","shell.execute_reply":"2024-12-29T05:50:31.511376Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Define Custom Dataset Class\n","metadata":{}},{"cell_type":"code","source":"class CreateDataset(Dataset):\n    def __init__(self, df_data, data_dir='../input/', transform=None):\n        super().__init__()\n        self.df = df_data.values\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        img_name, label = self.df[index]\n        img_path = os.path.join(self.data_dir, img_name + '.png')\n        image = cv2.imread(img_path)\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:31.513142Z","iopub.execute_input":"2024-12-29T05:50:31.513634Z","iopub.status.idle":"2024-12-29T05:50:31.519331Z","shell.execute_reply.started":"2024-12-29T05:50:31.513592Z","shell.execute_reply":"2024-12-29T05:50:31.518450Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Image transformations","metadata":{}},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.4),\n    transforms.RandomRotation(15),  \n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), \n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n])\n\ntest_transforms = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:31.520917Z","iopub.execute_input":"2024-12-29T05:50:31.521177Z","iopub.status.idle":"2024-12-29T05:50:31.532829Z","shell.execute_reply.started":"2024-12-29T05:50:31.521152Z","shell.execute_reply":"2024-12-29T05:50:31.532160Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Load the training Data\n","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/aptos2019-blindness-detection/train_images\"\ntrain_csv = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/train.csv')\ntrain_data = CreateDataset(df_data=train_csv, data_dir=train_path, transform=train_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:31.533770Z","iopub.execute_input":"2024-12-29T05:50:31.534022Z","iopub.status.idle":"2024-12-29T05:50:31.556716Z","shell.execute_reply.started":"2024-12-29T05:50:31.533970Z","shell.execute_reply":"2024-12-29T05:50:31.556172Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Split Training Data into Training and Validation Data","metadata":{}},{"cell_type":"code","source":"train_indices, valid_indices = train_test_split(np.arange(len(train_data)), test_size=0.2, random_state=42)\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(valid_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:31.557504Z","iopub.execute_input":"2024-12-29T05:50:31.557702Z","iopub.status.idle":"2024-12-29T05:50:31.563492Z","shell.execute_reply.started":"2024-12-29T05:50:31.557681Z","shell.execute_reply":"2024-12-29T05:50:31.562800Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Data Loaders","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import WeightedRandomSampler\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# class_counts = train_csv['diagnosis'].value_counts().sort_index().values\n# class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float).to(device)\n\n# sample_weights = class_weights[train_csv['diagnosis'].values]\n# sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\ntrainloader = DataLoader(train_data, batch_size=32, sampler= train_sampler, num_workers=4)\nvalidloader = DataLoader(train_data, batch_size=32, sampler=valid_sampler, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:31.564364Z","iopub.execute_input":"2024-12-29T05:50:31.564616Z","iopub.status.idle":"2024-12-29T05:50:31.656955Z","shell.execute_reply.started":"2024-12-29T05:50:31.564592Z","shell.execute_reply":"2024-12-29T05:50:31.656107Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Model Setup","metadata":{}},{"cell_type":"code","source":"model = models.efficientnet_b3(pretrained=True) \nnum_ftrs = model.classifier[1].in_features \nout_ftrs = 5\nmodel.classifier = nn.Sequential(\n    nn.Linear(num_ftrs, 512),\n    nn.ReLU(),\n    nn.Linear(512, out_ftrs),\n    nn.LogSoftmax(dim=1)\n)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:50:58.824463Z","iopub.execute_input":"2024-12-29T05:50:58.824811Z","iopub.status.idle":"2024-12-29T05:50:59.370830Z","shell.execute_reply.started":"2024-12-29T05:50:58.824780Z","shell.execute_reply":"2024-12-29T05:50:59.369938Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n      )\n      (5): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Linear(in_features=1536, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=5, bias=True)\n    (3): LogSoftmax(dim=1)\n  )\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Loss and optimizer","metadata":{}},{"cell_type":"code","source":"\ncriterion = nn.NLLLoss()\n\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00001, weight_decay=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:17.169165Z","iopub.execute_input":"2024-12-29T05:51:17.169511Z","iopub.status.idle":"2024-12-29T05:51:17.176097Z","shell.execute_reply.started":"2024-12-29T05:51:17.169479Z","shell.execute_reply":"2024-12-29T05:51:17.175050Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Function to Train and Validate Model","metadata":{}},{"cell_type":"code","source":"def train_and_validate(epochs, freeze_until = 3, unfreeze_step = 4):\n    valid_loss_min = np.Inf\n    train_losses, valid_losses, acc = [], [], []\n    \n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Unfreeze the final layer initially for training\n    for param in model.classifier.parameters():\n        param.requires_grad = True\n\n    unfreeze_counter = 0\n    \n    for epoch in range(epochs):\n        if epoch >= freeze_until and unfreeze_counter < len(list(model.children())):\n            \n            layers_to_unfreeze = list(model.children())[unfreeze_counter:unfreeze_counter + unfreeze_step]\n            for layer in layers_to_unfreeze:\n                for param in layer.parameters():\n                    param.requires_grad = True\n            print(f\"Unfreezing layers from index {unfreeze_counter} to {unfreeze_counter + unfreeze_step - 1} at epoch {epoch + 1}.\")\n            unfreeze_counter += unfreeze_step\n            \n        model.train()\n        running_loss = 0\n        \n        for images, labels in trainloader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        # Validation\n        model.eval()\n        test_loss = 0\n        accuracy = 0\n        with torch.no_grad():\n            for images, labels in validloader:\n                images, labels = images.to(device), labels.to(device)\n                logps = model(images)\n                test_loss += criterion(logps, labels).item()\n                ps = torch.exp(logps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n        \n        # Average losses and accuracies\n        train_loss = running_loss / len(trainloader)\n        valid_loss = test_loss / len(validloader)\n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        acc.append(accuracy / len(validloader))\n        print(f\"Epoch: {epoch+1}/{epochs}.. \"\n              f\"Training Loss: {train_loss:.3f}.. \"\n              f\"Validation Loss: {valid_loss:.3f}.. \"\n              f\"Validation Accuracy: {accuracy / len(validloader):.3f}\")\n\n        # Save the model if validation loss has decreased\n        if valid_loss < valid_loss_min:\n            print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': valid_loss_min\n            }, 'best_model.pth')\n            valid_loss_min = valid_loss\n\nprint('Training Completed Successfully!')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:20.022831Z","iopub.execute_input":"2024-12-29T05:51:20.023649Z","iopub.status.idle":"2024-12-29T05:51:20.034577Z","shell.execute_reply.started":"2024-12-29T05:51:20.023604Z","shell.execute_reply":"2024-12-29T05:51:20.033668Z"}},"outputs":[{"name":"stdout","text":"Training Completed Successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Execute","metadata":{}},{"cell_type":"code","source":"train_and_validate(epochs=20, freeze_until = 2, unfreeze_step = 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:53:26.046612Z","iopub.execute_input":"2024-12-29T05:53:26.047503Z","iopub.status.idle":"2024-12-29T06:53:29.798679Z","shell.execute_reply.started":"2024-12-29T05:53:26.047467Z","shell.execute_reply":"2024-12-29T06:53:29.797522Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1/20.. Training Loss: 1.391.. Validation Loss: 1.334.. Validation Accuracy: 0.505\nValidation loss decreased (inf --> 1.334299).  Saving model ...\nEpoch: 2/20.. Training Loss: 1.249.. Validation Loss: 1.229.. Validation Accuracy: 0.553\nValidation loss decreased (1.334299 --> 1.229269).  Saving model ...\nUnfreezing layers from index 0 to 1 at epoch 3.\nEpoch: 3/20.. Training Loss: 1.082.. Validation Loss: 0.999.. Validation Accuracy: 0.656\nValidation loss decreased (1.229269 --> 0.999302).  Saving model ...\nUnfreezing layers from index 2 to 3 at epoch 4.\nEpoch: 4/20.. Training Loss: 0.921.. Validation Loss: 0.880.. Validation Accuracy: 0.719\nValidation loss decreased (0.999302 --> 0.880476).  Saving model ...\nEpoch: 5/20.. Training Loss: 0.831.. Validation Loss: 0.817.. Validation Accuracy: 0.733\nValidation loss decreased (0.880476 --> 0.817135).  Saving model ...\nEpoch: 6/20.. Training Loss: 0.780.. Validation Loss: 0.768.. Validation Accuracy: 0.738\nValidation loss decreased (0.817135 --> 0.767675).  Saving model ...\nEpoch: 7/20.. Training Loss: 0.745.. Validation Loss: 0.740.. Validation Accuracy: 0.737\nValidation loss decreased (0.767675 --> 0.739801).  Saving model ...\nEpoch: 8/20.. Training Loss: 0.706.. Validation Loss: 0.705.. Validation Accuracy: 0.744\nValidation loss decreased (0.739801 --> 0.705356).  Saving model ...\nEpoch: 9/20.. Training Loss: 0.684.. Validation Loss: 0.689.. Validation Accuracy: 0.745\nValidation loss decreased (0.705356 --> 0.688637).  Saving model ...\nEpoch: 10/20.. Training Loss: 0.646.. Validation Loss: 0.677.. Validation Accuracy: 0.745\nValidation loss decreased (0.688637 --> 0.676527).  Saving model ...\nEpoch: 11/20.. Training Loss: 0.638.. Validation Loss: 0.660.. Validation Accuracy: 0.751\nValidation loss decreased (0.676527 --> 0.660075).  Saving model ...\nEpoch: 12/20.. Training Loss: 0.614.. Validation Loss: 0.629.. Validation Accuracy: 0.770\nValidation loss decreased (0.660075 --> 0.628742).  Saving model ...\nEpoch: 13/20.. Training Loss: 0.603.. Validation Loss: 0.603.. Validation Accuracy: 0.775\nValidation loss decreased (0.628742 --> 0.602543).  Saving model ...\nEpoch: 14/20.. Training Loss: 0.575.. Validation Loss: 0.594.. Validation Accuracy: 0.778\nValidation loss decreased (0.602543 --> 0.594493).  Saving model ...\nEpoch: 15/20.. Training Loss: 0.559.. Validation Loss: 0.584.. Validation Accuracy: 0.788\nValidation loss decreased (0.594493 --> 0.583813).  Saving model ...\nEpoch: 16/20.. Training Loss: 0.560.. Validation Loss: 0.600.. Validation Accuracy: 0.780\nEpoch: 17/20.. Training Loss: 0.530.. Validation Loss: 0.581.. Validation Accuracy: 0.782\nValidation loss decreased (0.583813 --> 0.581439).  Saving model ...\nEpoch: 18/20.. Training Loss: 0.527.. Validation Loss: 0.568.. Validation Accuracy: 0.790\nValidation loss decreased (0.581439 --> 0.567884).  Saving model ...\nEpoch: 19/20.. Training Loss: 0.520.. Validation Loss: 0.552.. Validation Accuracy: 0.803\nValidation loss decreased (0.567884 --> 0.551881).  Saving model ...\nEpoch: 20/20.. Training Loss: 0.510.. Validation Loss: 0.542.. Validation Accuracy: 0.797\nValidation loss decreased (0.551881 --> 0.542467).  Saving model ...\n","output_type":"stream"}],"execution_count":13}]}